{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e0ffa89",
   "metadata": {},
   "source": [
    "<h1>Code for Experiment 311</h1>\n",
    "\n",
    "This notebook contains all of the code used to process the data in Experiment 311."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adef0cc3",
   "metadata": {},
   "source": [
    "<h2>Importing data and modules</h2>\n",
    "\n",
    "The modules used in this code were numpy, matplotlib.pyplot and the gamma function from scipy.special.\n",
    "\n",
    "Firstly, the data needed to be read into Python as a numpy array. This was complicated by the fact that the data was in five minute chunks. To combine the data, it was read into a list as separate arrays, modified so that it contained the correct time, and then concatenated together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a9aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import gamma\n",
    "\n",
    "B = []\n",
    "for i in range(14):\n",
    "    b0 = np.zeros((3000000, 3))\n",
    "    b0[:, 0] = i*np.ones(3000000)*3000000 # Shifting counts accordingly.\n",
    "    b0[:, 1] = i*np.ones(3000000)*300 # Shifting time accordingly.\n",
    "    # B += [np.loadtxt(f\".\\\\Data\\\\NuclearCounting{i+1}.txt\", delimiter=', ') + b0]  # Importing and putting data into a list.\n",
    "    B += [np.loadtxt(f\"C:\\\\Users\\\\bayle\\\\OneDrive\\\\Documents\\\\University Documents\\\\2022 S1\\\\PHYSICS 390\\\\Experiment 311\\\\Data\\\\NuclearCounting{i+1}.txt\", delimiter=', ') + b0]  # Importing and putting data into a list.\n",
    "\n",
    "A = B[0]\n",
    "for i in range(13):\n",
    "    A = np.concatenate((A, B[i+1])) # Iteratively combining the data.\n",
    "count = A[:, 0]\n",
    "time = A[:, 1]\n",
    "volt = A[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7883b7c",
   "metadata": {},
   "source": [
    "Next, the peaks in the voltage needed to be recorded. As pointed out in the report, a deviation of $4\\sigma$ from the mean seemed to be adequate to capture the peaks.\n",
    "\n",
    "To encode peaks, the array `countfin` was constructed, which was essentially a function of the count: if a peak had started at the input count, then the output was 1, and otherwise it was 0. The array was constructed by iterating through the counts, first asking if the voltage was below $\\mu - 4\\sigma$, and second asking if the previous count was below $\\mu - 4\\sigma$. The second step was done by creating a toggle, which turned on when the threshold was reached.\n",
    "\n",
    "To encode distances between peaks, `countd` was constructed. This was essentially done by iterating through countfin, finding when it was 1, and adding the corresponding count to `countd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4825d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(volt)\n",
    "sigma = np.std(volt)\n",
    "\n",
    "countfin = np.zeros(len(count)) # Initializing countfin.\n",
    "\n",
    "First = 1 # Toggle.\n",
    "\n",
    "for i in range(len(count)): \n",
    "    if volt[i] <= mean - 4*sigma: # If the signal is significantly low,\n",
    "        if NotFirst == 1: # and this is the first time in a while,\n",
    "            countfin[i] = 1 # then a peak has started.\n",
    "            First = 0 # No longer the first count below the peak.\n",
    "    if volt[i] > mean - 4*sigma: # When the peak ends,\n",
    "        First = 1 # the next dip below the threshold will be the first.\n",
    "\n",
    "# The last array records the exact counts at which peaks are.\n",
    "countd = np.array([i for i in range(len(countfin)) if countfin[i]==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9fbb72",
   "metadata": {},
   "source": [
    "<h2>Constancy Check</h2>\n",
    "\n",
    "Before the data could be interpreted, the constancy of the rate of counts needed to be verified. In this section the data was divided into 60-second intervals, and the number of counts in each interval was recorded. Then a line was fitted to the data, and the result was plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7011fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tc = 60 # Time interval for the constancy check\n",
    "\n",
    "N = int(time[-1]/Tc) # The number of intervals\n",
    "cnum = int(count[-1]/N) # The number of datapoints per interval\n",
    "\n",
    "peakcount = np.zeros(N) # peakcount is the no. of peaks in each interval.\n",
    "for i in range(N):\n",
    "    ci = i*cnum # Starting count for the ith interval\n",
    "    peakcount[i] = np.sum(countfin[ci:(ci+cnum)])\n",
    "\n",
    "Z = np.arange(N)\n",
    "p = np.polyfit(Z, parray, 1) # Fitted line\n",
    "print(f'The slope of the line is {p[0]:.3g}.')\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Counts per Minute')\n",
    "plt.xlabel('Time (min)')\n",
    "plt.ylabel('Counts')\n",
    "plt.plot(Z, peakcount, label='Data')\n",
    "plt.plot(Z, Z*p[0] + p[1], color='red', label='Fitted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516993c9",
   "metadata": {},
   "source": [
    "<h2>Poisson Distribution</h2>\n",
    "\n",
    "The Poisson distribution was the first that was tested, and to do so an interval length needed to be chosen. The distribution has a distinctive shape when the mean counts per interval is between 3 and 6, so the time interval was chosen so that this number was 4.5. The rest of the data analysis is self-explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a3147",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcr = np.sum(countfin)/time[-1] # Mean count rate; number of counts over time.\n",
    "Tp = 4.5/mcr # explained above\n",
    "Np = int(time[-1]/Tp) # Total number of intervals.\n",
    "cnump = int(count[-1]/N) # Number of datapoints in each interval.\n",
    "\n",
    "peakcountp = np.zeros(Np) # peakcountp is the no. of peaks within an interval.\n",
    "for i in range(Np):\n",
    "    ci = i*cnump\n",
    "    peakcountp[i] = np.sum(countfin[ci:(ci+cnump)])\n",
    "\n",
    "countmeanp = np.mean(peakcountp) # Mean number of peaks in each interval.\n",
    "countstdp = np.std(peakcountp) # SD of the number of peaks in each interval.\n",
    "print(f'The mean of the distribution is {countmean:.4g}, and the variance is {countstd**2:.4g}.')\n",
    "\n",
    "def f(x, mu, sigma): # Expected PDF for a Gaussian.\n",
    "    return 1/(sigma*np.sqrt(2*np.pi))*np.exp(-((x - mu)/sigma)**2)\n",
    "\n",
    "def PMF(k, lam): # Poisson PMF, made continuous using the gamma function.\n",
    "    return lam**k*np.exp(-lam)/gamma(k+1)\n",
    "\n",
    "# Plotting.\n",
    "plt.figure()\n",
    "plt.title('Histogram of Counts in 0.68s Intervals')\n",
    "plt.xlabel('Number of Counts in Interval')\n",
    "plt.ylabel('Proportion of Intervals')\n",
    "plt.hist(peakcountp, bins=int(max(peakcountp) - min(peakcountp)), density=True, rwidth=0.9, align='left', label='Measured')\n",
    "plt.plot(np.arange(min(peakcountp), max(peakcountp), 0.01), \\\n",
    "         PMF(np.arange(min(peakcountp), max(peakcountp), 0.01), countmeanp),\\\n",
    "         color='red', label='Predicted')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Gaussian Fit to 0.68s Intervals')\n",
    "plt.xlabel('Number of Counts in Interval')\n",
    "plt.ylabel('Proportion of Intervals')\n",
    "plt.hist(peakcountp, bins=int(max(peakcountp) - min(peakcountp)), density=True, rwidth=0.9, align='left', label='Measured')\n",
    "plt.plot(np.arange(min(peakcountp), max(peakcountp), 0.01), \\\n",
    "         f(np.arange(min(peakcountp), max(peakcountp), 0.01), countmeanp, countstdp), \\\n",
    "         color='red', label='Gaussian')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Implementation of the trapezoid method to find the expected number of intervals\n",
    "# with a certain number of peaks i, according to the Poisson distribution (wrong=0)\n",
    "# and the Gaussian distribution (wrong=1).\n",
    "def expect(i, wrong=0): \n",
    "    if wrong==0:\n",
    "        return PMF(i, countmeanp)\n",
    "    else:\n",
    "        return 0.5*(f(i, countmeanp, countstdp) + f(i+1, countmeanp, countstdp))\n",
    "\n",
    "# Number of considered peak counts (since the others are all zero).\n",
    "binsp = max(peakcountp) - min(peakcountp)\n",
    "\n",
    "# histarray is an array of bins.\n",
    "histarray = np.arange(min(peakcountp), binno+min(peakcountp))\n",
    "Ep = expect(histarray)\n",
    "Ewrong = expect(histarray, wrong=1)\n",
    "\n",
    "def observed(array): # Number of observed intervals with a given peak count, as in 'array'.\n",
    "    k = np.zeros(len(array))\n",
    "    for i in range(len(array)): # Running through peak counts.\n",
    "        for j in range(len(peakcountp)): # Running through intervals.\n",
    "            if peakcountp[j] == array[i]: # If the number of peaks in the examined interval is equal to the desired peak count array[i],\n",
    "                k[i] += 1 # increment the number in the ith position by 1.\n",
    "    return k # The output of the function is as follows: for the ith peak count in array, k[i] is the number of intervals containing array[i] peaks.\n",
    "\n",
    "O = observed(histarray)/Np # Normalizing.\n",
    "\n",
    "chisquarep = np.sum((O - Ep)**2/Ep) # Chisquare value according to Poisson\n",
    "chisquarewrong = np.sum((O - Ewrong)**2/Ewrong) # Chisquare value according to Gaussian\n",
    "print(f'The \\u03C7\\u00B2 value for the Poisson fit is {chisquarep:.4g}.')\n",
    "print(f'The \\u03C7\\u00B2 value for the Gaussian fit is {chisquarewrong:.4g}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c185e38",
   "metadata": {},
   "source": [
    "<h2>Gaussian Distribution</h2>\n",
    "\n",
    "The Gaussian distribution was the second to be tested. Since the data only appears Gaussian for large mean counts, the interval was chosen so that the mean count per interval was between 200 and 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tg = 240/mcr # explained above\n",
    "Ng = int(time[-1]/Tg) # Total number of intervals.\n",
    "cnumg = int(count[-1]/N) # Number of datapoints in each interval.\n",
    "\n",
    "peakcountg = np.zeros(Ng) # peakcountp is the no. of peaks within an interval.\n",
    "for i in range(Ng):\n",
    "    ci = i*cnumg\n",
    "    peakcountg[i] = np.sum(countfin[ci:(ci+cnumg)])\n",
    "\n",
    "countmeang = np.mean(peakcountg) # Mean number of peaks in each interval.\n",
    "countstdg = np.std(peakcountg) # SD of the number of peaks in each interval.\n",
    "print(f'The mean of the distribution is {countmean:.4g}, and the variance is {countstd**2:.4g}.')\n",
    "\n",
    "# Plotting.\n",
    "plt.figure()\n",
    "plt.title('Histogram of Counts in 36s Intervals')\n",
    "plt.xlabel('Number of Counts in Interval')\n",
    "plt.ylabel('Proportion of Intervals')\n",
    "plt.hist(peakcountg, bins=int(max(peakcountg) - min(peakcountg)), density=True, rwidth=0.9, align='left', label='Measured')\n",
    "plt.plot(np.arange(min(peakcountg), max(peakcountg), 0.01), \\\n",
    "         f(np.arange(min(peakcountp), max(peakcountg), 0.01), countmeang, countstdg), color='red', label='Predicted')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "def expectg(i): \n",
    "    return 0.5*(f(i, countmeang, countstdg) + f(i+1, countmeang, countstdg))\n",
    "\n",
    "# Number of considered peak counts (since the others are all zero).\n",
    "binsg = max(peakcountg) - min(peakcountg)\n",
    "\n",
    "# histarray is an array of bins.\n",
    "histarray = np.arange(min(peakcountg), binno+min(peakcountg))\n",
    "Eg = expectg(histarray)\n",
    "\n",
    "def observed(array): # Number of observed intervals with a given peak count, as in 'array'.\n",
    "    k = np.zeros(len(array))\n",
    "    for i in range(len(array)): # Running through peak counts.\n",
    "        for j in range(len(peakcountg)): # Running through intervals.\n",
    "            if peakcountg[j] == array[i]: # If the number of peaks in the examined interval is equal to the desired peak count array[i],\n",
    "                k[i] += 1 # increment the number in the ith position by 1.\n",
    "    return k # The output of the function is as follows: for the ith peak count in array, k[i] is the number of intervals containing array[i] peaks.\n",
    "\n",
    "O = observed(histarray)/Ng # Normalizing.\n",
    "\n",
    "chisquareg = np.sum((O - Eg)**2/Eg) # Chisquare value according to Gaussian\n",
    "print(f'The \\u03C7\\u00B2 value for the Gaussian fit is {chisquareg:.4g}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6053d07",
   "metadata": {},
   "source": [
    "<h2>Exponential Distribution</h2>\n",
    "\n",
    "The exponential distribution was the third to be tested. The bin size was chosen to be 0.25s, simply because it best represented the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d47de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "countdiff = np.zeros(len(countd) - 1) # countdiff is an array of count differences between peaks.\n",
    "for i in range(len(countdiff)):\n",
    "    countdiff[i] = countd[i+1] - countd[i] # Taking differences of all peak counts.\n",
    "timediff = countdiff/10000 # Sample rate of 10kHz; timediff is time differences between peaks.\n",
    "\n",
    "diffmean = np.mean(timediff) # Mean time difference.\n",
    "diffstd = np.std(timediff) # Standard deviation of time difference.\n",
    "\n",
    "tau = 1/mcr # by definition of mean time interval\n",
    "def W(t): # Expected PDF for an exponential distribution.\n",
    "    return (1/tau)*np.exp(-t/tau)\n",
    "\n",
    "# Plotting.\n",
    "t = np.arange(0, max(timediff), 0.01)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Histogram of Intervals between Decays')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Proportion of Intervals')\n",
    "plt.hist(timediff, bins=np.arange(0, 2, 0.1), density=True, rwidth=0.9, label='Measured')\n",
    "plt.plot(t, W(t), color='red', label='Predicted')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "def expect(i): # Use of the trapezoid rule to find the expected probability.\n",
    "    return 0.5*(W(i) + W(i+0.1))\n",
    "\n",
    "binsexp = int(2/0.1) # Number of bins.\n",
    "\n",
    "histarray = np.arange(0, 2, 0.1)\n",
    "E = expect(histarray)\n",
    "\n",
    "def observed(array):\n",
    "    k = np.zeros(len(array))\n",
    "    for i in range(len(array) - 1):\n",
    "        for j in range(len(timediff)):\n",
    "            if timediff[j] >= array[i] and timediff[j] < array[i+1]:\n",
    "                k[i] += 1\n",
    "    \n",
    "    return k\n",
    "\n",
    "O = observed(X)/len(timediff)*10\n",
    "\n",
    "chisquareexp = np.sum((O-E)**2/E)\n",
    "print(f'The \\u03C7\\u00B2 value for the Gaussian fit is {chisquareexp:.4g}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0162b04",
   "metadata": {},
   "source": [
    "<h2>Critical $\\chi^2$ Values</h2>\n",
    "\n",
    "To calculate the critical $\\chi^2$ values for the report, the quantile function for the $\\chi^2$ distribution was constructed directly. This was done using the PDF for the distribution given in [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3ddb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import gamma\n",
    "from scipy.optimize import root_scalar\n",
    "from scipy.integrate import quad\n",
    "\n",
    "def chisq(x, k): # There are two definitions: one for numbers, and one for arrays. This was primarily done for testing.\n",
    "    if type(x) == float or type(x) == int:\n",
    "        if x == 0:\n",
    "            return 0\n",
    "        return x**(k/2-1)*np.exp(-x/2)/(gamma(k/2)*2**(k/2))\n",
    "    if type(x) == np.ndarray:\n",
    "        ar = np.zeros(len(x))\n",
    "        for i in range(len(x)):\n",
    "            if x[i] == 0:\n",
    "                ar[i] = 0\n",
    "            else:\n",
    "                ar[i] = x[i]**(k/2-1)*np.exp(-x[i]/2)/(gamma(k/2)*2**(k/2))\n",
    "        return ar\n",
    "    \n",
    "\n",
    "def CDF(x, k):\n",
    "    if type(x) == float or type(x) == int:\n",
    "        return quad(chisq, 0, x, args=(k))[0]\n",
    "    if type(x) == np.ndarray:\n",
    "        ar = np.zeros(len(x))\n",
    "        for i in range(len(x)):\n",
    "            ar[i] = quad(chisq, 0, x[i], args=(k))[0]\n",
    "        return ar\n",
    "\n",
    "def f(x, k, alpha): # The function which is zero at the relevant quantile.\n",
    "    return CDF(x, k) - 1 + alpha\n",
    "\n",
    "def quantile(alpha, k, x0=0, x1=100):\n",
    "    return root_scalar(f, args=(k, alpha), x0=x0, x1=x1) # The secant method was used to construct the quantile function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dc8e53",
   "metadata": {},
   "source": [
    "<h2>Addenda</h2>\n",
    "\n",
    "There were some extra graphs drawn, for illustration purposes or for extra analysis. The first cell shows the graphs for the first decay and the first three seconds of data, while the second cell analyses the background radiation collected over 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ecd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2400\n",
    "M = 2650\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Single Decay')\n",
    "plt.plot(time[m:M], volt[m:M])\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Voltage (V)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('First Three Seconds of Data')\n",
    "plt.plot(time[:30000], volt[:30000])\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Voltage (V)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.loadtxt(\".\\\\Data\\\\NuclearCountingAmb.txt\", delimiter=', ')\n",
    "count0 = C[:,0]\n",
    "time0 = C[:,1]\n",
    "volt0 = C[:,2]\n",
    "\n",
    "mean0 = np.mean(volt0)\n",
    "sigma0 = np.std(volt0)\n",
    "\n",
    "countfin0 = np.zeros(len(count0)) # Countfin is a peak array, as above.\n",
    "\n",
    "First = 1\n",
    "\n",
    "for i in range(len(count0)):\n",
    "    if volt0[i] <= mean0 - 4*sigma0:\n",
    "        if First == 1:\n",
    "            countfin0[i] = 1\n",
    "            First = 0\n",
    "    if volt0[i] > mean0 - 4*sigma0:\n",
    "        First = 1\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(count0[:100000], volt0[:100000])\n",
    "plt.show()\n",
    "\n",
    "print(np.sum(countfin0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
